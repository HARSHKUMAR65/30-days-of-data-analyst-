# -*- coding: utf-8 -*-
"""Day 7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IABkHfZ--wj3RXgUUqk777J03nlGFY_n

# **hello everone **
today We have  dataset contains insightful information related to insurance claims, giving us an in-depth look into the demographic patterns of those receiving them. The dataset contains information on patient age, gender, BMI (Body Mass Index), blood pressure levels, diabetic status, number of children, smoking status and region. By analyzing these key factors across geographical areas and across different demographics such as age or gender we can gain a greater understanding of who is most likely to receive an insurance claim. This understanding gives us valuable insight that can be used to inform our decision making when considering potential customers for our services. On a broader scale it can inform public policy by allowing for more targeted support for those who are most in need and vulnerable. These kinds of insights are extremely valuable and this dataset provides us with the tools we need to uncover them!
 this notebook, we will take a closer look at Insurance Claims and figure out some facts about how conditions such as blood pressure, BMI, diabetes, smoking, age, and gender impact the claim value.
 Later we build model and evaluate it
"""

# import libraries
import pandas as pd              ## Data preprocessesing 
import numpy as np               ## Mathematical calculation 
import seaborn as sns            ## Data vizualizatiom 
import matplotlib.pyplot as plt  ##Data vizualization

## import the data 
data=pd.read_csv("/content/insurance_data.csv")

## top 5 rows of ddata 
data.head()

## cheaking dtypes 
data.info()

## Staatical view 
data.describe()

## cheaking null value 
data.isnull().sum()

## interploting the null value 
data=data.interpolate()  #numeric_values
data=data.fillna(data.mode().iloc[0])   #categorical features 
data.isnull().sum() ## cheaking null values again

## remove unnessesry_columns
data.drop(columns=['index','PatientID'],axis=1,inplace=True)

data

"""# EDA"""

##cheaking  relationship between variables useing heatmap 
plt.figure(figsize=(10,10))
sns.heatmap(data=data.corr(),annot=True,cmap='crest')
plt.show()

plt.figure(figsize=(20,12))
sns.set(style="whitegrid")
cols=["age","bmi","bloodpressure","children","claim"]
sns.pairplot(data[cols],height=2.5)
plt.show()

from pandas.plotting import scatter_matrix
sm = scatter_matrix(data, figsize=(10, 10))





























new_data=data.copy()

##import additional library for   model 
from sklearn.preprocessing import LabelEncoder                    ## for encodeing columns
from sklearn.preprocessing import StandardScaler                  ## for zero mean one standard deviation 
from sklearn.model_selection import train_test_split,cross_val_score             ## for split the data into training and testing phase 
from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error       ## for  observing result



from sklearn.linear_model import LinearRegression   # linear_regression
from sklearn.linear_model import Ridge               #ridge_regression
from sklearn.linear_model import Lasso            # Lasso_regression
from sklearn.linear_model import ElasticNet           #Elastic_net
from sklearn.ensemble import RandomForestRegressor      #random_forset_regressor
from sklearn.svm import SVR             # supportvector_ regressor
from xgboost import XGBRegressor  #  xgboost_regressor

# Label_encodeing
le=LabelEncoder()
new_data['gender']=le.fit_transform(new_data['gender'])
new_data['diabetic']=le.fit_transform(new_data['diabetic'])
new_data['smoker']=le.fit_transform(new_data['smoker'])
new_data['region']=le.fit_transform(new_data['region'])


new_data.head()

## standard scaler
scaler = StandardScaler()
scaler_data=scaler.fit_transform(new_data.drop(columns=['claim']))

scaler_data

##spliting the data for training and testing phase 
x_train,x_test,y_train,y_test=train_test_split(scaler_data,new_data['claim'],test_size=0.2,random_state=42)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

def rmse_cv(model):
    rmse = np.sqrt(-cross_val_score(model, scaler_data, new_data['claim'], scoring="neg_mean_squared_error", cv=5)).mean()
    return rmse
    

def evaluation(y, predictions):
    mae = mean_absolute_error(y, predictions)
    mse = mean_squared_error(y, predictions)
    rmse = np.sqrt(mean_squared_error(y, predictions))
    r_squared = r2_score(y, predictions)
    return mae, mse, rmse, r_squared

models = pd.DataFrame(columns=["Model","MAE","MSE","RMSE","R2 Score","RMSE (Cross-Validation)"])

"""## Linear_regression"""

lin_reg = LinearRegression()
lin_reg.fit(x_train, y_train)
predictions = lin_reg.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(lin_reg)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "LinearRegression","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Ridge_regression"""

ridge = Ridge()
ridge.fit(x_train, y_train)
predictions = ridge.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(ridge)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "Ridge","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Lasso_regression"""

lasso = Lasso()
lasso.fit(x_train, y_train)
predictions = lasso.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(lasso)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "Lasso","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Elastic_net"""

elastic_net = ElasticNet()
elastic_net.fit(x_train, y_train)
predictions = elastic_net.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(elastic_net)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "ElasticNet","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Support Vector Machines"""

svr = SVR(C=100000)
svr.fit(x_train, y_train)
predictions = svr.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(svr)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "SVR","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Random_forest_regressor"""

random_forest = RandomForestRegressor(n_estimators=100)
random_forest.fit(x_train, y_train)
predictions = random_forest.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(random_forest)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "RandomForestRegressor","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## XGBOOST_regressor"""

xgb = XGBRegressor(n_estimators=1000, learning_rate=0.01)
xgb.fit(x_train, y_train)
predictions = xgb.predict(x_test)

mae, mse, rmse, r_squared = evaluation(y_test, predictions)
print("MAE:", mae)
print("MSE:", mse)
print("RMSE:", rmse)
print("R2 Score:", r_squared)
print("-"*30)
rmse_cross_val = rmse_cv(xgb)
print("RMSE Cross-Validation:", rmse_cross_val)

new_row = {"Model": "XGBRegressor","MAE": mae, "MSE": mse, "RMSE": rmse, "R2 Score": r_squared, "RMSE (Cross-Validation)": rmse_cross_val}
models = models.append(new_row, ignore_index=True)

"""## Model_Comparision
Less the root_mean_squared_error  the better the model is
"""

models.sort_values(by="RMSE (Cross-Validation)")

plt.figure(figsize=(12,8))
sns.barplot(x=models["Model"], y=models["RMSE (Cross-Validation)"])
plt.title("Models' RMSE Scores (Cross-Validated)", size=15)
plt.xticks(rotation=30, size=12)
plt.show()

