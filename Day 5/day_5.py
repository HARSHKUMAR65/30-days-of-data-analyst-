# -*- coding: utf-8 -*-
"""Day 5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CHctNMOkeXT4nEMILY2-oVdFzHWwhHu_

# Spotify-DataAnalysis
 Today we Analysis and clustering of popular songs and their attributes u

Python's spotipy library is used to get data from Spotify. By doing searches with characters(A-Z, 0-9) 1750 songs were collected. These songs are shared in the .csv file.

Numerical features provided by spotify are collected and analyzed. K-Means Clustering Algorithm is used to group songs that are similar to each other.
"""

# import libraries
import pandas as pd  # used for data preprocessesing 
import numpy as np  # used for methamatical calculation 
import seaborn as sns  # used for vizualization 
import matplotlib.pyplot as plt  # used for vizualization 
from sklearn.preprocessing import StandardScaler # covert zero mean one standard deviation 
from sklearn.cluster import KMeans

# Import data 
data=pd.read_csv("/content/spotify_data.csv")
# drop  useless columns
data.drop(columns=['Unnamed: 0'],axis=1,inplace=True)

#first five rows of data 
data.head()

# Cheaking missing value 
data.isnull().sum()

#cheaking dtype 
data.info()

#statisical  look 
data.describe()

## shape of data
data.shape

data.drop_duplicates(keep='first',inplace=True)

data.sort_values("popularity",ascending=False)

"""# Analysis

here We cheak the relationship between  all columns  useing  heatmap
"""

plt.figure(figsize=(15,15))
sns.heatmap(data.corr(),annot=True,cmap='crest')
plt.show()

plt.figure(figsize=(20,12))
sns.set(style="whitegrid")
cols=["popularity","acousticness","instrumentalness","speechiness","danceability","energy"]
sns.pairplot(data[cols],height=2.5)
plt.show()

"""## Here we have artist who have high popularity in this data """

popular_songs=data.sort_values('popularity',ascending=False)
artist_with_popularity=popular_songs[['artist','popularity']]
artist_with_popularity

plt.figure(figsize=(14,6))
sns.barplot(x=artist_with_popularity.artist.head(10),y=artist_with_popularity.popularity.head(10))

"""now we cheak the song which have high popularities """

popular_songs=data.sort_values('popularity',ascending=False)
songs_with_popularity=popular_songs[['name','popularity']]
songs_with_popularity


plt.figure(figsize=(14,6))
sns.barplot(x=songs_with_popularity.head(5).name,y=songs_with_popularity.popularity)
plt.legend()

"""Now we cheak that which album have highest songs """

data['album'].value_counts().head(10).plot(figsize=(15,7),kind='pie',)

"""## Preprocessing And Clustering

Droping the feature who wont use in clustering  popularity is not nessessery  because we only inspect popular songs
"""

data2= data.select_dtypes(include = ['int64','float64']).drop(columns=['popularity'])

data2

scaler=StandardScaler()
data2=pd.DataFrame(scaler.fit_transform(data2),columns=data2.columns)
data2

wcss=[]
for i in range(1,11):
  model=KMeans(n_clusters=i,init='k-means++',n_init=10,max_iter=1000,random_state=42)
  model.fit(data2)
  wcss.append(model.inertia_)

wcss

plt.plot(range(1,11),wcss)
plt.title("the elbow metheod graph")
plt.xlabel("no of cluster")
plt.ylabel("wcss")
plt.show()

"""we decided to chose 4 as our k train our model for last time and predict the cluster """

kmean=KMeans(n_clusters=4,init='k-means++',max_iter=500,n_init=10,random_state=0)
y_kmean=kmean.fit_predict(data2)

data['cluster']=y_kmean
data.head()

cluster_0=data[data['cluster']==0]
cluster_1=data[data['cluster']==1]
cluster_2=data[data['cluster']==2]
cluster_3=data[data['cluster']==3]

data.cluster.value_counts()

cluster_0.head(2)

cluster_1.head(2)

cluster_2.head(2)

cluster_3.head(2)

